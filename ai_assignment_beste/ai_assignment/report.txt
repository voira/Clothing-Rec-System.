1. I extracted the image features using a pre-trained model and added these values as columns as input space alongside a normalized barcode and encoded brand column. At first I started out with one hot encoding however there were too many empty values for some columns and when it was one-hot encoded the output matrix would become not only too large but also too sparse as some values were really rare and the model would just say those features don't exist and would obtain a decent accuracy. To avoid this result without having to sample synthetic data, I encoded the output values the same way I encoded the brands for it to become a multi-level and multi-label prediction problem. Since I already had the feature vectors of the images, I created a 3-layer MLP instead of a CNN that would get the features from scratch as this proved to be more time efficient for me. The model ends with a SoftMax activation function and it has a relatively high learning rate as we do not have many data points to learn from.

On second week I pivoted from an MLP model to a CNN. The training was relatively easy. The hard part was the selection of the loss function alongside the normalized labels which then had to be denormalized for seeing which label it actually assigned instead of a fraction. While I was visualizing the data I realized some images are of a model and you don't know which part of the outfit we are actually categorizing. This issue seemed ok to me because in a realistic situation there is always the picture of just the product by itself so I decided to not spend extra time over it. 

The main issue I had was trying to decrease the loss more and more with each model iterations. I tried to allocate my GPU most efficiently to do it both fast and keep the image fidelity intact. I also thought the image number was too low for a CNN to be trained from scratch.
After trying to tune my model with multiple embeddings I wanted try again with one hot encoding instead one more time using the CNN. This is the model that showed a really nice performance on the test set accuracy. You can find this iteration names as Part1_2. I wanted to keep both of the files to show all my work. 

At this stage the input is only the image itself and no brand or barcode information is necessary but the barcode is still indexed in the data.csv file for item identification. It is trivial to pull the brands into the barcodes. One additional step here is to de encode th one hot encoding into actual variable names but I think this task in itself is not that difficult to achieve and I used the already existing labels in the following parts so I found leaving it as is to be sufficient for this examination task

2. I built a very basic recommandation algorithm which is especially accurate in recommending shirts according to body type. This is so because according to the information I gathered the tops are much more important compared to bottoms or skirts. I tried to use every detail label to categorize it according to body type that was already in the dataset. 

3. For the third exercise I used flask to send API calls into the development server using the additional sorting options eg. category == dress etc. I implemented one but this could easily be extended to other sorting options which is then considered with the simple recommandation algorithm. I also wanted  to containerize my entire application so I added a dockerfile and a recommandation.txt file into my folder. This way you would be able to run my code without any problems on a browser notebook environment. 